# 阶段一：Sprint 详细计划（第1-2月）

**阶段目标**: 实现 MVP，验证技术可行性，完成首批试点
**时间跨度**: 8周（4个Sprint）
**团队规模**: 6人（技术负责人1 + 后端2 + 前端1 + AI工程师1 + DevOps 0.5 + PM 0.5）

---

## Sprint 0：准备冲刺（第0周，启动前）

### 目标
搭建开发环境，明确技术选型，组建团队

### 任务清单

#### 团队组建（3天）
- [ ] 确定技术负责人
- [ ] 招募/调配后端工程师（2人）
- [ ] 招募/调配前端工程师（1人）
- [ ] 招募/调配 AI 工程师（1人）
- [ ] 协调 DevOps 支持（0.5人）
- [ ] 产品经理介入（0.5人）

#### 环境准备（3天）
- [ ] 申请 Gemini API Key（配额：10M tokens/月）
- [ ] 申请 Claude API Key（备用）
- [ ] 申请 OpenAI API Key（备用）
- [ ] 搭建 K8s 开发环境（本地 minikube + 云端测试集群）
- [ ] 配置 CI/CD Pipeline（GitLab CI / GitHub Actions）
- [ ] 准备测试用 GitLab 实例
- [ ] 准备测试用 GitHub 仓库

#### 技术选型确认（2天）
- [ ] 后端框架：NestJS + TypeScript
- [ ] 数据库：PostgreSQL 15 + Redis 7 + MongoDB 6
- [ ] 前端框架：React 18 + Vite + Ant Design Pro
- [ ] 队列：BullMQ
- [ ] 监控：Prometheus + Grafana

#### 项目初始化（2天）
- [ ] 创建代码仓库（Monorepo 或多仓库）
- [ ] 配置 ESLint + Prettier
- [ ] 配置 Husky（Git Hooks）
- [ ] 编写基础 README
- [ ] 配置 Docker Compose（本地开发）

### 验收标准
- ✅ 团队到位，角色明确
- ✅ 开发环境就绪，所有成员可以启动项目
- ✅ AI API 可调用
- ✅ CI/CD Pipeline 跑通

---

## Sprint 1：核心框架搭建（第1-2周）

### Sprint 目标
搭建后端 API 框架、数据库 Schema、前端基础页面，实现第一个端到端流程

### 故事点（Story Points）: 34 点

---

### 后端任务（16 点）

#### 1. 数据库设计和迁移（5 点）
**负责人**: 后端工程师1
**任务**:
- [ ] 使用 Prisma 定义 Schema
  - Organization, Department, User 模型
  - Service, ServiceConfig 模型
  - Review, Violation 模型（基础版）
- [ ] 编写数据库迁移脚本
- [ ] 编写 Seed 数据（测试用）
- [ ] PostgreSQL + Redis + MongoDB 容器化配置

**验收标准**:
- Schema 符合设计文档
- 迁移脚本可重复执行
- Seed 数据包含 1 个组织、2 个用户、1 个服务

---

#### 2. Webhook 服务（6 点）
**负责人**: 后端工程师2
**任务**:
- [ ] GitLab Webhook Controller
  - 接收 Push Hook
  - 接收 Merge Request Hook
  - 签名验证（X-Gitlab-Token）
- [ ] GitHub Webhook Controller
  - 接收 push 事件
  - 接收 pull_request 事件
  - HMAC 签名验证
- [ ] Webhook 事件解析
  - 提取 commit hash, author, branch
  - 提取文件变更列表
  - 区分事件类型（Push/PR/MR）
- [ ] 任务队列集成（BullMQ）
  - 将 Webhook 事件加入队列
  - 优先级计算（根据文件数量）

**验收标准**:
- 使用 Postman 模拟 Webhook 请求，成功入队
- 签名验证通过/失败的单元测试
- 队列中可以看到任务

---

#### 3. AI 调度器（基础版）（5 点）
**负责人**: AI 工程师
**任务**:
- [ ] AI Channel 配置管理
  - 支持配置 Gemini/Claude/GPT-4 API Key
  - 基础负载均衡（Round Robin）
- [ ] Gemini API 集成
  - 封装 API 调用
  - 处理速率限制（Rate Limit）
  - 重试机制（指数退避）
- [ ] Claude API 集成（备用）
- [ ] Token 使用量统计
  - 记录每次调用的 input/output tokens
  - 存储到 AIUsage 表

**验收标准**:
- 成功调用 Gemini API 生成代码审查
- 成功调用 Claude API（备用）
- Token 使用量正确记录到数据库

---

### 前端任务（8 点）

#### 4. 前端框架搭建（3 点）
**负责人**: 前端工程师
**任务**:
- [ ] Vite + React + TypeScript 项目初始化
- [ ] 配置 Ant Design Pro
- [ ] 配置路由（React Router v6）
- [ ] 配置状态管理（Zustand）
- [ ] 配置 API 请求（Axios + TanStack Query）
- [ ] 登录/注销功能（JWT）

**验收标准**:
- 可访问前端页面
- 登录后可获取 JWT Token
- API 请求自动带 Token

---

#### 5. 服务管理页面（5 点）
**负责人**: 前端工程师
**任务**:
- [ ] 服务列表页
  - 表格展示所有服务
  - 支持搜索、筛选
- [ ] 添加服务表单
  - 服务名称、Git 地址、Git Provider（GitLab/GitHub）
  - Webhook Secret 生成
  - 保存到后端
- [ ] 服务详情页（占位）

**验收标准**:
- 可以添加一个新服务
- 服务列表可以显示已添加的服务
- Webhook Secret 自动生成

---

### DevOps 任务（5 点）

#### 6. 部署和监控（5 点）
**负责人**: DevOps 工程师
**任务**:
- [ ] Docker Compose 配置
  - 后端服务
  - PostgreSQL, Redis, MongoDB
  - 前端（Nginx）
- [ ] K8s 部署配置（开发环境）
  - Deployment, Service, Ingress
  - ConfigMap, Secret
- [ ] Prometheus + Grafana 部署
  - 基础监控指标（CPU, Memory, Request）
- [ ] 日志收集（ELK Stack 或 Loki）

**验收标准**:
- 使用 `docker-compose up` 可启动完整系统
- K8s 开发环境可访问
- Grafana 可以查看基础指标

---

### PM 任务（5 点）

#### 7. 文档和测试计划（5 点）
**负责人**: 产品经理
**任务**:
- [ ] 编写用户手册（如何添加服务）
- [ ] 编写测试用例文档
  - Webhook 触发流程测试
  - 服务管理功能测试
- [ ] 准备演示数据
- [ ] 组织 Sprint Review（第2周五）

**验收标准**:
- 用户手册可读性良好
- 测试用例覆盖主要流程
- Sprint Review PPT 准备完毕

---

### Sprint 1 验收标准（DoD）
- ✅ 后端 API 可以接收 Webhook 事件
- ✅ 前端可以添加服务并配置 Webhook
- ✅ AI API 调用成功
- ✅ 开发环境可部署
- ✅ 监控系统就绪

---

## Sprint 2：审查引擎核心（第3-4周）

### Sprint 目标
实现审查引擎核心逻辑，支持 Go 语言审查，生成审查报告

### 故事点: 42 点

---

### 后端任务（24 点）

#### 1. 审查引擎（10 点）
**负责人**: 后端工程师1
**任务**:
- [ ] 审查引擎服务（ReviewEngineService）
  - 从队列消费任务
  - 调用 Git API 获取文件变更
  - 构建审查上下文（ReviewContext）
  - 调度 AI 审查
  - 生成审查报告
- [ ] Git 集成服务（GitService）
  - GitLab API 集成（@gitbeaker/rest）
    - 获取 Merge Request 详情
    - 获取文件变更（diff）
    - 发布评论到 MR
  - GitHub API 集成（@octokit/rest）
    - 获取 Pull Request 详情
    - 获取文件变更
    - 发布评论到 PR
- [ ] 审查报告生成
  - 整体评分计算
  - 分类评分（安全、质量、性能）
  - 违规列表整理
  - Markdown 格式化

**验收标准**:
- 提交代码后自动触发审查
- 可以获取 GitLab MR 的文件变更
- 可以获取 GitHub PR 的文件变更
- 生成的报告格式良好

---

#### 2. 规则引擎（基础版）（8 点）
**负责人**: 后端工程师2
**任务**:
- [ ] 规则数据模型（ReviewRule）
  - 规则定义（name, description, prompt）
  - 适用语言和框架
  - 严重级别
- [ ] Go 语言规则库（10 条）
  - 安全规则（3 条）：
    - SQL 注入检测
    - 硬编码密钥检测
    - 不安全的文件操作
  - 质量规则（4 条）：
    - 函数复杂度检查
    - 未处理的 error 返回值
    - 不推荐的命名规范
    - 缺少注释
  - 性能规则（3 条）：
    - 循环中的字符串拼接
    - 不必要的内存分配
    - Goroutine 泄漏风险
- [ ] 规则匹配引擎
  - 根据语言筛选规则
  - 应用规则到代码变更
  - 调用 AI 检查规则违规
- [ ] 规则 Seed 数据

**验收标准**:
- 数据库中有 10 条 Go 规则
- 规则匹配引擎可以筛选适用规则
- AI 可以根据规则检查代码

---

#### 3. Prompt 工程（6 点）
**负责人**: AI 工程师
**任务**:
- [ ] PR 级别审查 Prompt
  - 输入：PR 描述、文件列表、diff
  - 输出：整体评价、风险分析、建议
- [ ] 文件级别审查 Prompt
  - 输入：文件名、语言、diff、适用规则
  - 输出：文件级评价、问题列表
- [ ] 规则检查 Prompt
  - 输入：规则描述、代码片段
  - 输出：是否违规、违规位置、修复建议
- [ ] Few-shot 示例
  - 为每种 Prompt 准备 2-3 个示例
- [ ] Prompt 模板管理
  - 支持从配置文件加载 Prompt
  - 支持变量替换

**验收标准**:
- PR 级别 Prompt 可以生成合理的整体评价
- 文件级别 Prompt 可以识别问题
- 规则检查 Prompt 准确率 > 70%

---

### 前端任务（10 点）

#### 4. 审查记录页面（6 点）
**负责人**: 前端工程师
**任务**:
- [ ] 审查记录列表
  - 表格展示（服务名、事件类型、分支、作者、得分、状态、时间）
  - 支持筛选（按服务、按状态、按时间）
  - 支持搜索（按 commit hash）
  - 分页
- [ ] 审查详情页（基础版）
  - 显示整体得分
  - 显示分类得分（安全、质量、性能）
  - 显示违规列表（文件、行号、严重程度、消息）
  - 链接到 Git 平台查看原始 PR/MR

**验收标准**:
- 可以查看所有审查记录
- 可以进入审查详情页查看完整报告
- 筛选和搜索功能正常

---

#### 5. 基础仪表盘（4 点）
**负责人**: 前端工程师
**任务**:
- [ ] 总览卡片
  - 今日审查次数
  - 本周审查次数
  - 发现问题总数
  - 平均得分
- [ ] 趋势图表（ECharts）
  - 审查次数趋势（近7天）
  - 平均得分趋势（近7天）
  - 问题分布（饼图：安全/质量/性能）

**验收标准**:
- 仪表盘可以显示关键指标
- 图表数据正确
- 图表样式美观

---

### 测试任务（8 点）

#### 6. 端到端测试（8 点）
**负责人**: 全团队
**任务**:
- [ ] 编写 E2E 测试用例
  - 添加服务 → 配置 Webhook → 提交代码 → 触发审查 → 查看报告
- [ ] 准备测试仓库
  - 包含 Go 代码，有意引入安全/质量/性能问题
- [ ] 执行测试并修复 Bug
- [ ] 性能测试
  - 审查时长是否 < 60s
  - 并发 5 个 PR 审查

**验收标准**:
- E2E 测试通过
- 审查时长 < 60s
- 并发审查不崩溃

---

### Sprint 2 验收标准（DoD）
- ✅ 提交 Go 代码后自动触发审查
- ✅ 审查报告发布到 GitLab MR / GitHub PR
- ✅ 审查准确率 > 70%
- ✅ 审查时长 < 60s
- ✅ 前端可以查看审查记录和详情

---

## Sprint 3：多语言支持和通知系统（第5-6周）

### Sprint 目标
扩展到 Python 和 TypeScript，实现通知系统

### 故事点: 38 点

---

### 后端任务（20 点）

#### 1. Python 语言支持（6 点）
**负责人**: 后端工程师2
**任务**:
- [ ] Python 规则库（10 条）
  - 安全：SQL 注入、pickle 使用、路径遍历
  - 质量：PEP 8 规范、类型注解、异常处理
  - 性能：列表推导式、生成器使用
- [ ] Python 专用 Prompt
- [ ] 语言检测逻辑（根据文件扩展名）

**验收标准**:
- 可以审查 Python 代码
- 规则触发正常

---

#### 2. TypeScript 语言支持（6 点）
**负责人**: 后端工程师1
**任务**:
- [ ] TypeScript 规则库（10 条）
  - 安全：XSS 风险、eval 使用、敏感信息泄漏
  - 质量：any 类型滥用、未使用变量、重复代码
  - 性能：不必要的重渲染（React）、大数组操作
- [ ] TypeScript 专用 Prompt
- [ ] 框架检测（React/Vue）

**验收标准**:
- 可以审查 TypeScript/React 代码
- 框架特定问题可以识别

---

#### 3. 通知服务（8 点）
**负责人**: 后端工程师2
**任务**:
- [ ] 通知配置模型（ServiceConfig.notificationChannels）
- [ ] 通知服务接口
  - Email 通知（Nodemailer）
  - 企业微信通知（Webhook）
  - Slack 通知（可选）
- [ ] 通知内容模板
  - 审查完成通知
  - 严重问题告警
- [ ] 通知触发逻辑
  - 审查完成时发送
  - 发现 Critical 问题时立即发送
- [ ] 通知配置继承
  - Service → Department → Organization

**验收标准**:
- 审查完成后收到邮件通知
- 发现严重问题后收到企业微信通知
- 通知内容格式良好

---

### AI 任务（8 点）

#### 4. Prompt 优化和测试（8 点）
**负责人**: AI 工程师
**任务**:
- [ ] 收集前 2 个 Sprint 的审查结果
- [ ] 分析误报案例
  - 哪些规则误报率高？
  - 哪些 Prompt 输出不稳定？
- [ ] 优化 Prompt
  - 增加 Few-shot 示例
  - 调整温度参数（temperature）
  - 添加输出格式约束
- [ ] A/B 测试
  - 新旧 Prompt 对比测试（至少 20 个 PR）
  - 记录准确率变化
- [ ] 多模型对比
  - Gemini vs Claude vs GPT-4
  - 记录成本、速度、准确率

**验收标准**:
- 准确率从 70% 提升到 75%+
- 误报率下降
- A/B 测试报告完成

---

### 前端任务（6 点）

#### 5. 服务配置页面（6 点）
**负责人**: 前端工程师
**任务**:
- [ ] 服务详情页增强
  - 基本信息
  - Webhook 配置（URL、Secret）
  - 审查规则配置
    - 选择启用的规则
    - 规则优先级排序
  - 通知配置
    - 添加邮件通知
    - 添加企业微信通知
    - 选择通知触发条件
  - 保存配置
- [ ] 配置预览
  - 显示继承的配置（灰色）
  - 显示当前服务的配置（高亮）

**验收标准**:
- 可以配置服务的规则和通知
- 配置保存后生效
- 配置继承正确显示

---

### 测试任务（4 点）

#### 6. 多语言测试（4 点）
**负责人**: 全团队
**任务**:
- [ ] 准备 Python 测试仓库
- [ ] 准备 TypeScript/React 测试仓库
- [ ] 执行端到端测试
- [ ] 验证通知功能

**验收标准**:
- Python 审查通过
- TypeScript 审查通过
- 通知收到

---

### Sprint 3 验收标准（DoD）
- ✅ 支持 Go、Python、TypeScript 三种语言
- ✅ 邮件和企业微信通知正常
- ✅ 准确率 > 75%
- ✅ 配置功能完善

---

## Sprint 4：试点和优化（第7-8周）

### Sprint 目标
内部试点，收集反馈，优化体验

### 故事点: 30 点

---

### 试点推广（10 点）

#### 1. 试点团队招募（3 点）
**负责人**: 产品经理
**任务**:
- [ ] 选择 3-5 个试点团队
  - 技术栈：Go/Python/TypeScript
  - 团队规模：5-10 人
  - 意愿度：高
- [ ] 沟通试点计划
  - 试点目标
  - 时间安排
  - 支持方式
- [ ] 准备试点材料
  - 用户手册
  - 培训 PPT
  - FAQ 文档

**验收标准**:
- 3 个试点团队确认参加
- 试点材料准备完毕

---

#### 2. 启动仪式和培训（4 点）
**负责人**: 产品经理 + 技术负责人
**任务**:
- [ ] 组织启动会议（1 小时）
  - 产品介绍
  - 演示"AI 如何帮我找 bug"
  - Q&A
- [ ] 现场支持
  - 帮助团队添加服务
  - 配置 Webhook
  - 验证第一次审查
- [ ] 建立支持渠道
  - 企业微信群
  - 专人支持（1 小时内响应）

**验收标准**:
- 启动会议完成
- 3 个团队成功接入
- 支持渠道建立

---

#### 3. 反馈收集（3 点）
**负责人**: 产品经理
**任务**:
- [ ] 每日 NPS 问卷（1-5 分）
- [ ] 每周深度访谈（3 个用户）
- [ ] GitHub Issue 跟踪
- [ ] 误报反馈专用通道

**验收标准**:
- 收集到至少 20 份 NPS 反馈
- 完成 3 次深度访谈
- Issue 列表建立

---

### 优化任务（12 点）

#### 4. Bug 修复和体验优化（12 点）
**负责人**: 全团队
**任务**:
- [ ] 修复试点中发现的 Bug（优先级 P0-P1）
- [ ] 性能优化
  - 审查时长优化（目标 < 45s）
  - 并发能力提升
  - 缓存优化
- [ ] 体验优化
  - 前端交互优化
  - 报告可读性提升
  - 错误提示优化
- [ ] 准确率优化
  - Prompt 调优
  - 规则优化
  - 误报处理

**验收标准**:
- P0-P1 Bug 全部修复
- 审查时长 < 45s
- 准确率 > 80%

---

### 文档和总结（8 点）

#### 5. 文档完善（4 点）
**负责人**: 产品经理
**任务**:
- [ ] 用户手册更新
  - 根据试点反馈完善
  - 增加常见问题
  - 增加最佳实践
- [ ] 开发者文档
  - API 文档（Swagger）
  - 架构文档
  - 部署文档
- [ ] 运维手册
  - 监控指标说明
  - 告警处理流程
  - 故障恢复流程

**验收标准**:
- 文档完整可读
- 新用户可以根据文档自助接入

---

#### 6. 阶段总结（4 点）
**负责人**: 技术负责人 + 产品经理
**任务**:
- [ ] 数据统计
  - 接入项目数
  - 活跃用户数
  - 审查次数
  - 发现问题数
  - 准确率、误报率
  - 用户满意度
- [ ] 编写阶段总结报告
  - 目标达成情况
  - 关键成果
  - 遇到的问题
  - 经验教训
- [ ] 汇报 PPT
- [ ] 组织阶段评审会议

**验收标准**:
- 阶段总结报告完成
- 评审会议完成
- 获得继续推进的批准

---

### Sprint 4 验收标准（DoD）
- ✅ 3 个试点团队成功接入
- ✅ 用户满意度 > 4.0
- ✅ 准确率 > 80%
- ✅ 审查时长 < 45s
- ✅ 阶段总结完成

---

## 阶段一总验收标准

### 功能验收
- ✅ 支持 GitLab 和 GitHub 集成
- ✅ 支持 Go、Python、TypeScript 三种语言
- ✅ 规则库包含 30+ 条规则
- ✅ 邮件和企业微信通知正常
- ✅ Web 管理后台完整可用
- ✅ 监控和日志系统就绪

### 质量验收
- ✅ 审查准确率 > 80%
- ✅ 误报率 < 20%
- ✅ 审查时长(P95) < 45s
- ✅ 系统可用性 > 99%

### 业务验收
- ✅ 3 个项目成功接入
- ✅ 25+ 活跃用户
- ✅ 日均审查次数 > 10
- ✅ 用户满意度 > 4.0

---

## 风险和应对

### 高风险

| 风险 | 缓解措施 |
|------|---------|
| AI 准确率不达标 | 多模型对比，Prompt 快速迭代，设置置信度阈值 |
| 审查时长过长 | 并发优化，缓存优化，增量审查 |
| 试点用户抵触 | 渐进式推广，透明化，快速响应反馈 |
| 成本超预算 | 优先使用 Gemini，设置配额限制，监控成本 |

### 快速失败指标
- ❌ 准确率 < 60% 连续 3 天 → 暂停，优化 Prompt
- ❌ NPS < 3.0 连续 1 周 → 访谈用户，调整策略
- ❌ 系统崩溃 > 2 次/周 → 修复稳定性问题

---

## 附录

### 每周节奏

**周一**:
- Sprint Planning（Sprint 开始周）
- Stand-up（9:30 AM，15 分钟）
- 技术分享（可选，30 分钟）

**周二-周四**:
- Stand-up（9:30 AM）
- Pair Programming（鼓励）

**周五**:
- Stand-up（9:30 AM）
- Sprint Review（Sprint 结束周，1 小时）
- Sprint Retrospective（Sprint 结束周，30 分钟）
- 团队聚餐（可选）

### 沟通渠道

- **即时沟通**: 企业微信群
- **任务管理**: Jira / Linear / GitHub Projects
- **文档协作**: Confluence / Notion
- **代码评审**: GitHub / GitLab MR
- **技术讨论**: RFC 文档

### 定义完成（Definition of Done）

每个任务必须满足：
- [ ] 代码已提交并通过 Code Review
- [ ] 单元测试覆盖率 > 80%
- [ ] 集成测试通过
- [ ] 文档已更新（API 文档、用户文档）
- [ ] 无 P0-P1 Bug
- [ ] 产品经理验收通过
