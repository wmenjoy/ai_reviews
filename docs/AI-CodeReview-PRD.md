# AI代码审核平台 - 产品需求文档(PRD)

**文档版本**: v3.0
**创建日期**: 2025年
**最后更新**: 2025年1月28日
**产品负责人**: [待填写]

---

## 1. 产品概述

### 1.1 产品定位

企业级AI代码审核平台，为研发团队提供**自动化、智能化的代码质量保障**，覆盖从代码提交到合并的全流程。

### 1.2 产品愿景

- **短期目标**（6个月）：成为公司内所有项目的标配工具，100%覆盖关键业务代码
- **中期目标**（1年）：沉淀公司级代码规范和最佳实践，技术债务下降30%
- **长期目标**（3年）：打造智能代码助手，不仅审核还能辅助编码

### 1.3 目标用户

| 角色 | 占比 | 典型场景 | 核心诉求 |
|------|------|----------|----------|
| **开发工程师** | 60% | 日常开发提交代码 | 快速反馈、准确建议、不误报 |
| **Tech Lead** | 15% | 负责团队代码质量 | 团队质量趋势、技术债务可视化 |
| **部门经理** | 10% | 管理多个团队 | 跨团队对比、质量报表 |
| **架构师** | 10% | 关注架构和安全 | 严重问题告警、专家审核 |
| **平台管理员** | 5% | 维护审核平台 | 配置管理、权限控制 |

### 1.4 核心价值主张

**对开发者**：
- ⚡ **即时反馈**：5分钟内获得审核结果
- 🎯 **精准建议**：针对具体代码行给出修复建议
- 📚 **知识学习**：了解最佳实践，提升编码能力

**对团队**：
- 📏 **统一规范**：建立团队代码标准
- 📈 **质量提升**：持续改善代码质量
- 💡 **知识沉淀**：最佳实践可复用

**对企业**：
- 🛡️ **降低风险**：提前发现安全漏洞
- 💰 **节省成本**：减少人工Review时间
- 📊 **数据决策**：基于数据的质量管理

---

## 2. 用户故事 (User Stories)

### Epic 1: 代码审核核心流程

#### Story 1.1: 作为开发者，我希望提交代码后自动触发审核
**优先级**: P0
**价值**: 让开发者无需额外操作即可获得审核

**场景描述**：
```
Given 我已经将代码推送到GitLab/GitHub
When Push事件被平台接收
Then 自动触发代码审核
And 在企业微信收到审核开始通知
And 审核完成后在MR中看到评论
```

**验收标准**：
- [ ] 支持GitLab Push和Merge Request事件
- [ ] 支持GitHub Push和Pull Request事件
- [ ] Webhook签名验证通过
- [ ] 5分钟内开始审核
- [ ] 审核结果自动发布到Git平台

**技术要点**：
- Webhook接收服务
- 事件解析和验证
- 优先级队列

---

#### Story 1.2: 作为开发者，我希望看到清晰的审核结果和修复建议
**优先级**: P0
**价值**: 让开发者快速理解问题并修复

**场景描述**：
```
Given 我的代码已经审核完成
When 我打开Merge Request
Then 我看到AI发布的审核评论
And 评论中包含：
  - 总体得分
  - 问题列表（按严重程度分类）
  - 每个问题的具体位置（文件:行号）
  - 问题描述和修复建议
And 我可以点击问题跳转到对应代码行
```

**验收标准**：
- [ ] GitLab MR中显示格式化的审核评论
- [ ] GitHub PR中显示Review Comments
- [ ] 问题按严重程度分类（严重/错误/警告）
- [ ] 每个问题包含文件路径和行号
- [ ] 提供具体的修复建议代码

**界面示例**：
```markdown
## ✅ AI代码审核结果

**得分**: 85/100
**总结**: 代码整体质量良好，有2个需要修复的问题

### 🚨 严重问题 (1个)

- **UserService.java:45** - SQL注入风险
  ```java
  // 问题代码
  String sql = "SELECT * FROM users WHERE name = '" + userName + "'";

  // 建议修复
  String sql = "SELECT * FROM users WHERE name = ?";
  PreparedStatement stmt = conn.prepareStatement(sql);
  stmt.setString(1, userName);
  ```

### ⚠️ 警告 (3个)
<details>
<summary>点击查看</summary>

- **OrderService.java:123** - 方法过长，建议拆分
- **PaymentService.java:67** - 缺少日志记录
...
</details>

[查看完整报告](https://code-review.company.com/review/abc123)
```

---

#### Story 1.3: 作为开发者，我希望只审核我修改的代码，而不是整个项目
**优先级**: P0
**价值**: 提高审核效率，避免历史问题干扰

**场景描述**：
```
Given 我修改了3个文件
When 触发审核
Then 只审核这3个文件的变更部分
And 历史遗留问题不出现在本次审核中
And 审核报告中明确标注"新增问题" vs "历史问题"
```

**验收标准**：
- [ ] 只审核Git diff中的变更
- [ ] 区分新增问题和历史问题
- [ ] 基线对比功能
- [ ] 跳过自动生成的文件（package-lock.json等）

---

### Epic 2: 多语言和多平台支持

#### Story 2.1: 作为Java开发者，我希望平台能识别Java特有的问题
**优先级**: P0
**价值**: 提供针对性的审核建议

**场景描述**：
```
Given 我提交了一段Java代码
When 代码中包含Spring Boot注解
Then 平台能检测Spring相关的最佳实践
  例如：
  - @Transactional使用是否正确
  - @Autowired vs 构造器注入
  - Controller层是否过重
And 能检测Java通用问题
  - 空指针风险
  - 资源泄漏
  - 并发安全
```

**验收标准**：
- [ ] 支持Java/Kotlin语法识别
- [ ] 内置10+条Spring Boot规则
- [ ] 内置20+条Java通用规则
- [ ] 能识别MyBatis SQL注入
- [ ] 能检测线程安全问题

---

#### Story 2.2: 作为Go开发者，我希望平台能检测Goroutine泄漏
**优先级**: P0
**价值**: 防止Go特有的并发问题

**场景描述**：
```
Given 我写了一段启动Goroutine的代码
When 忘记关闭对应的channel
Then 平台能检测到潜在的Goroutine泄漏
And 给出修复建议（如添加context.Cancel）
```

**验收标准**：
- [ ] 识别Goroutine泄漏风险
- [ ] 检测Channel使用问题
- [ ] 检测并发安全（race condition）
- [ ] 检测错误处理规范

---

#### Story 2.3: 作为前端开发者，我希望平台能检测React Hooks的依赖问题
**优先级**: P0

**场景描述**：
```
Given 我使用了useEffect Hook
When 依赖数组中缺少某个依赖
Then 平台能检测到并警告
And 建议完整的依赖数组
```

**验收标准**：
- [ ] 检测useEffect/useMemo/useCallback依赖
- [ ] 检测内存泄漏（事件监听未清理）
- [ ] 检测XSS风险（dangerouslySetInnerHTML）
- [ ] 支持Vue/React/TypeScript

---

#### Story 2.4: 作为C开发者，我希望平台能检测内存泄漏和缓冲区溢出
**优先级**: P0

**验收标准**：
- [ ] 检测malloc/free配对
- [ ] 检测数组越界风险
- [ ] 检测野指针
- [ ] 检测缓冲区溢出

---

#### Story 2.5: 作为Python开发者，我希望平台能检测SQL注入和pickle安全
**优先级**: P0

**验收标准**：
- [ ] 检测SQL注入（字符串拼接）
- [ ] 检测命令注入（os.system）
- [ ] 检测pickle反序列化风险
- [ ] 检测类型提示缺失

---

### Epic 3: 规则管理和定制

#### Story 3.1: 作为Tech Lead，我希望能为我的项目定制审核规则
**优先级**: P1
**价值**: 让审核符合团队实际情况

**场景描述**：
```
Given 我们团队有特定的编码规范
  例如：所有API接口必须有@RateLimit注解
When 我创建一条自定义规则
Then 我可以编写规则描述和Prompt
And 选择适用的语言（Java）
And 设置严重程度（ERROR）
And 规则立即生效
```

**验收标准**：
- [ ] 可视化规则编辑器
- [ ] 支持Prompt模板编写
- [ ] 支持正则匹配（可选）
- [ ] 规则测试功能（输入代码片段测试）
- [ ] 规则启用/禁用
- [ ] 规则优先级设置

**界面设计**：
```
创建自定义规则
┌─────────────────────────────────────────┐
│ 规则名称: [API接口限流检查            ] │
│                                         │
│ 描述: [检查所有Controller接口是否添加   │
│        @RateLimit注解                  ] │
│                                         │
│ 适用语言: ☑ Java  ☐ Go  ☐ Python      │
│                                         │
│ 类别: [安全 ▼]                          │
│ 严重程度: [错误 ▼]                      │
│                                         │
│ 检测方式:                                │
│ ◉ AI智能检测                            │
│ ○ 正则匹配                              │
│                                         │
│ Prompt模板: (AI如何检测此问题)          │
│ ┌─────────────────────────────────────┐ │
│ │检查代码中的@RestController类，       │ │
│ │查找所有public方法是否包含@RateLimit │ │
│ │注解。如果缺少，报告为ERROR。         │ │
│ └─────────────────────────────────────┘ │
│                                         │
│ 测试规则:                                │
│ 代码片段: [粘贴测试代码              ] │
│ [运行测试]                              │
│                                         │
│ [保存规则]                              │
└─────────────────────────────────────────┘
```

---

#### Story 3.2: 作为平台管理员，我希望能管理全局规则库
**优先级**: P1

**场景描述**：
```
Given 我是平台管理员
When 我进入规则管理页面
Then 我看到所有规则的列表
And 我可以：
  - 查看规则详情和使用统计
  - 启用/禁用规则
  - 编辑规则描述
  - 删除规则
  - 导入/导出规则
```

**验收标准**：
- [ ] 规则列表（支持搜索、筛选）
- [ ] 规则分类展示（安全/质量/性能/风格）
- [ ] 使用统计（触发次数、误报率）
- [ ] 批量操作（批量启用/禁用）
- [ ] 规则导入/导出（JSON格式）

---

#### Story 3.3: 作为用户，我希望能使用规则模板快速配置
**优先级**: P2

**场景描述**：
```
Given 我新建了一个Spring Boot项目
When 我需要配置审核规则
Then 我可以选择"Spring Boot微服务"模板
And 一键导入30+条最佳实践规则
And 可以根据需要微调
```

**验收标准**：
- [ ] 提供5+个官方模板
- [ ] 支持社区分享模板
- [ ] 模板预览功能
- [ ] 模板收藏和评分

---

### Epic 4: AI模型管理

#### Story 4.1: 作为管理员，我希望能配置多个AI模型并控制并发
**优先级**: P0
**价值**: 灵活控制成本和性能

**场景描述**：
```
Given 我有本地部署的AI模型和外部API
When 我配置AI模型
Then 我可以：
  - 添加本地模型（OpenAI兼容API）
  - 配置并发数（例如：4个并发）
  - 添加外部模型（Claude/GPT-4）
  - 设置优先级（本地优先，外部备用）
  - 设置负载均衡策略
```

**验收标准**：
- [ ] 支持添加多个AI模型
- [ ] 每个模型可配置并发数（1-20）
- [ ] 支持本地模型和外部模型
- [ ] 优先级设置
- [ ] 健康检查和自动降级
- [ ] 实时并发使用率监控

**界面设计**：
```
AI模型配置
┌─────────────────────────────────────────┐
│ + 添加模型                               │
├─────────────────────────────────────────┤
│ 模型列表:                                │
│                                         │
│ ┌─ 主力模型 (Qwen2.5-32B) ─────────┐   │
│ │ 状态: ✅ 运行中  使用率: 5/8      │   │
│ │ API: http://192.168.1.100:8000   │   │
│ │ 并发: ████████░░░░░░░░ 8         │   │
│ │ 优先级: 1 (最高)                  │   │
│ │ [编辑] [测试] [禁用]              │   │
│ └──────────────────────────────────┘   │
│                                         │
│ ┌─ 备用模型 (Claude 3.5) ──────────┐   │
│ │ 状态: ⏸️ 待机  使用率: 0/10       │   │
│ │ 提供商: Anthropic                 │   │
│ │ 优先级: 2                         │   │
│ │ 触发条件: 主力模型队列>20时       │   │
│ │ [编辑] [测试] [启用]              │   │
│ └──────────────────────────────────┘   │
│                                         │
│ 负载均衡策略: [优先级优先 ▼]           │
│ □ 启用多AI共识模式（成本较高）         │
│                                         │
└─────────────────────────────────────────┘
```

---

#### Story 4.2: 作为管理员，我希望能监控AI使用情况和成本
**优先级**: P1

**场景描述**：
```
Given 系统使用了多个AI模型
When 我查看AI使用统计
Then 我能看到：
  - 今日调用次数
  - Token使用量（输入/输出）
  - 预计费用
  - 按部门/服务/用户统计
  - 平均响应时间
```

**验收标准**：
- [ ] 实时调用次数统计
- [ ] Token使用量统计
- [ ] 成本计算和预测
- [ ] 多维度统计（部门/服务/用户）
- [ ] 性能监控（响应时间、成功率）

---

### Epic 5: 技术债务管理

#### Story 5.1: 作为Tech Lead，我希望能看到项目的技术债务概况
**优先级**: P1
**价值**: 可视化债务，制定优化计划

**场景描述**：
```
Given 项目已经运行了一段时间
When 我查看技术债务看板
Then 我能看到：
  - 总债务分数（0-100，越低越好）
  - 债务趋势图（最近3个月）
  - 问题分布（严重/错误/警告）
  - 债务最多的文件Top10
  - 自动生成的优化计划
```

**验收标准**：
- [ ] 债务总分计算
- [ ] 趋势图表（折线图）
- [ ] 问题分布饼图
- [ ] 文件热力图
- [ ] 自动优化建议

**界面设计**：
```
技术债务看板 - user-service
┌─────────────────────────────────────────┐
│ 总债务分数: 234 (↓ 下降8.5%)            │
│ ████████░░░░░░░░░░░░ 中等               │
│                                         │
│ 趋势 (最近3个月):                       │
│ 300│              ●                     │
│ 250│          ●       ●                 │
│ 200│      ●               ● ●          │
│    └────────────────────────            │
│     1月  2月  3月  4月  5月             │
│                                         │
│ 问题分布:                                │
│ 严重: 12 ████                           │
│ 错误: 45 ████████████                   │
│ 警告: 177 ████████████████████████      │
│                                         │
│ 债务热力图:                              │
│ UserService.java    ██████ 45个问题    │
│ OrderService.java   ████ 23个问题      │
│ PaymentUtil.java    ███ 18个问题       │
│                                         │
│ 🎯 自动优化建议:                        │
│ 1. 优先修复UserService.java中的        │
│    3个CRITICAL问题                      │
│ 2. 重构OrderService.processOrder方法   │
│    (过长，建议拆分)                      │
│                                         │
│ [生成修复计划] [导出报告]                │
└─────────────────────────────────────────┘
```

---

#### Story 5.2: 作为开发者，我希望清楚区分"新增问题"和"历史问题"
**优先级**: P1

**场景描述**：
```
Given 项目已经建立了基线
When 我提交新代码
Then 审核报告中明确标注：
  - 本次新增的问题（需要修复）
  - 历史遗留问题（可以暂时忽略）
And 只有新增问题会阻塞MR合并
```

**验收标准**：
- [ ] 基线建立和更新
- [ ] 新增问题标识
- [ ] 历史问题归档
- [ ] MR只检查新增问题

---

### Epic 6: 通知和集成

#### Story 6.1: 作为开发者，我希望在企业微信收到审核通知
**优先级**: P0

**场景描述**：
```
Given 我的代码审核完成
When 审核发现了问题
Then 我在企业微信收到通知
And 通知包含：
  - 服务名称和分支
  - 得分
  - 主要问题摘要
  - 查看详情链接
```

**验收标准**：
- [ ] 企业微信机器人集成
- [ ] Markdown格式通知
- [ ] 可配置通知条件（得分阈值）
- [ ] @提醒功能

---

#### Story 6.2: 作为管理员，我希望能配置多级通知策略
**优先级**: P1
**价值**: 灵活控制通知接收

**场景描述**：
```
Given 不同项目/部门有不同的通知需求
When 我配置通知策略
Then 我可以设置：
  - 项目级别的Webhook（优先级最高）
  - 人员级别的通知
  - 部门级别的通知
  - 全局默认通知
And 系统自动按优先级查找配置
```

**验收标准**：
- [ ] 四级配置（项目/人员/部门/默认）
- [ ] 优先级自动匹配
- [ ] 配置继承和覆盖
- [ ] 配置测试功能

---

### Epic 7: 权限和多租户

#### Story 7.1: 作为企业管理员，我希望能管理多个部门和团队
**优先级**: P1

**场景描述**：
```
Given 公司有多个部门
When 我配置组织架构
Then 我可以：
  - 创建部门
  - 分配部门管理员
  - 配置部门级AI配额
  - 查看部门审核统计
```

**验收标准**：
- [ ] 组织架构管理（公司/部门/用户）
- [ ] 部门管理员权限
- [ ] 数据隔离
- [ ] 部门统计报表

---

#### Story 7.2: 作为部门管理员，我只能看到和管理本部门的数据
**优先级**: P1

**验收标准**：
- [ ] 数据权限隔离
- [ ] 跨部门需要授权
- [ ] 审计日志

---

### Epic 8: 专家审核流程

#### Story 8.1: 作为架构师，当发现严重安全问题时，我希望被通知并参与审核
**优先级**: P2

**场景描述**：
```
Given AI发现了一个CRITICAL级别的SQL注入问题
When 问题被标记为"需要专家确认"
Then 自动@安全专家（我）
And 我可以：
  - 确认问题并要求修复
  - 标记为误报
  - 给予豁免通过（需要填写理由）
```

**验收标准**：
- [ ] 自动识别关键问题
- [ ] 专家池配置
- [ ] 自动分配专家
- [ ] 审核工作流
- [ ] 豁免记录可追溯

---

### Epic 9: IDE插件

#### Story 9.1: 作为开发者，我希望在VSCode中实时看到代码问题
**优先级**: P2

**场景描述**：
```
Given 我在VSCode中编写代码
When 我保存文件
Then IDE自动调用审核平台API
And 问题以波浪线标注在代码下
And 鼠标悬停可以看到详细说明
And 可以一键应用修复建议
```

**验收标准**：
- [ ] VSCode插件开发
- [ ] 保存时触发审核
- [ ] 问题可视化（Diagnostics）
- [ ] Quick Fix集成
- [ ] 配置审核模式

---

### Epic 10: 报表和数据分析

#### Story 10.1: 作为Tech Lead，我希望每周收到团队的代码质量报告
**优先级**: P2

**场景描述**：
```
Given 系统记录了一周的审核数据
When 周五下午5点
Then 我收到邮件报告
And 报告包含：
  - 本周审核数量
  - 平均得分和趋势
  - Top问题
  - 团队成员排名
  - 改进建议
```

**验收标准**：
- [ ] 周报自动生成
- [ ] 邮件发送
- [ ] PDF导出
- [ ] 数据可视化

---

### Epic 11: 多维度审核分析

#### Story 11.1: 作为开发者，我希望看到自己的代码质量画像
**优先级**: P1
**价值**: 让开发者了解自己的编码水平和成长轨迹

**场景描述**：
```
Given 我是一名开发者
When 我进入"我的质量中心"
Then 我能看到：
  - 我的质量总分（0-100）
  - 最近30天的质量趋势图
  - 我在团队中的排名
  - 我的强项和弱项分析（雷达图）
  - 我最常犯的错误Top5
  - 个性化改进建议
  - 我的成长轨迹
```

**验收标准**：
- [ ] 个人质量总分计算（加权平均：安全30%、质量30%、性能20%、规范20%）
- [ ] 30天趋势折线图
- [ ] 团队排名（可选隐藏，保护隐私）
- [ ] 能力雷达图展示多维能力（安全性、代码质量、性能、规范性）
- [ ] Top5问题统计（按出现频率）
- [ ] AI生成的个性化建议
- [ ] 成长轨迹时间线

**数据计算**：
- 质量总分 = 安全性×0.3 + 代码质量×0.3 + 性能×0.2 + 规范性×0.2
- 每个维度分数基于该维度问题数量和严重程度
- 每日凌晨计算并保存快照

---

#### Story 11.2: 作为开发者，我希望看到我负责的项目的质量状况
**优先级**: P1

**场景描述**：
```
Given 我负责多个项目
When 我切换到"我的项目"视图
Then 我能看到：
  - 我参与的所有项目列表
  - 每个项目的质量得分
  - 每个项目中我的贡献占比
  - 项目质量趋势
  - 我在该项目中的问题数
```

**验收标准**：
- [ ] 项目列表（按参与度或最近活跃排序）
- [ ] 项目质量卡片（得分、趋势、我的贡献）
- [ ] 个人贡献统计（提交次数、代码行数）
- [ ] 快速筛选（仅看我的提交）
- [ ] 跳转到项目详情

---

#### Story 11.3: 作为开发者，我希望和同事进行良性对比
**优先级**: P2
**价值**: 激励开发者提升代码质量，营造积极的技术氛围

**场景描述**：
```
Given 团队启用了"质量排行榜"
When 我查看排行榜
Then 我能看到：
  - 本周/本月综合质量排行Top10
  - 进步最快排行（本月vs上月）
  - 各语言质量冠军（Java冠军、Go冠军等）
  - 我的排名和排名变化
  - 我与上一名的差距
And 可以选择匿名显示（只看自己排名，不看他人）
```

**验收标准**：
- [ ] 多维度排行榜（总分/安全/质量/性能/规范）
- [ ] 进步榜（本月vs上月，按进步幅度排序）
- [ ] 语言榜（每种语言的Top3）
- [ ] 隐私保护（可选匿名模式）
- [ ] 游戏化元素（徽章、成就系统）
- [ ] 时间范围切换（本周/本月/本季度）

**游戏化元素**：
- 🥇 连续30天零CRITICAL问题
- 🌟 本月进步之星（进步最快）
- 🏆 质量守护者（连续3个月90分以上）
- 🎯 某语言专家（某语言得分95+）

---

#### Story 11.4: 作为部门经理，我希望看到部门整体质量状况
**优先级**: P1
**价值**: 帮助部门经理了解团队质量，制定改进计划

**场景描述**：
```
Given 我是部门经理
When 我进入"部门质量看板"
Then 我能看到：
  - 部门质量总分和趋势（最近6个月）
  - 部门在公司中的排名
  - 团队成员质量分布（直方图）
  - 项目质量排行
  - 高风险项目识别
  - 问题分布分析（安全/质量/性能/风格）
  - 需要关注的成员和项目
```

**验收标准**：
- [ ] 部门质量总分计算（团队成员加权平均）
- [ ] 趋势分析（周/月/季度可切换）
- [ ] 公司排名（与其他部门对比）
- [ ] 成员质量分布图（正态分布展示）
- [ ] 项目健康度雷达图
- [ ] 预警机制（质量下降超过10%时告警）
- [ ] 问题分布柱状图

---

#### Story 11.5: 作为部门经理，我希望能深入分析团队成员的质量数据
**优先级**: P1

**场景描述**：
```
Given 我需要了解团队成员的质量状况
When 我查看"成员质量详情"
Then 我能看到：
  - 每个成员的质量分数和趋势
  - 成员的强项和弱项
  - 成员的进步趋势
  - 需要帮助的成员识别（得分<70或下降趋势）
  - 优秀实践者识别（得分>90或上升趋势）
  - AI生成的一对一谈话建议
```

**验收标准**：
- [ ] 成员列表（可按得分、进步幅度、提交次数排序）
- [ ] 成员详情卡片（可展开/折叠）
- [ ] 成员对比功能（选择2-3个成员对比）
- [ ] 导出Excel报告（包含所有成员数据）
- [ ] AI生成的一对一建议（针对需要帮助的成员）
- [ ] 筛选功能（优秀/良好/需改进）

---

#### Story 11.6: 作为部门经理，我希望能识别团队的技能短板
**优先级**: P2

**场景描述**：
```
Given 部门有多个项目和多种技术栈
When 我查看"技能分析"
Then 我能看到：
  - 团队在各个维度的平均分
  - 相比其他部门的差距
  - 需要加强的技能领域
  - 培训建议和资源推荐
```

**验收标准**：
- [ ] 技能雷达图（团队平均 vs 公司平均）
- [ ] 部门对比（与其他部门的差距分析）
- [ ] 技能矩阵（人员-技能，显示每个人的擅长领域）
- [ ] 培训计划建议（基于短板自动推荐）

---

#### Story 11.7: 作为CTO，我希望看到全公司的代码质量全貌
**优先级**: P1
**价值**: 高层决策依据，了解整体技术健康度

**场景描述**：
```
Given 我是CTO/技术VP
When 我进入"全局质量看板"
Then 我能看到：
  - 公司整体质量得分和年度趋势
  - 各部门质量对比（排行榜）
  - 各语言质量对比（Java/Go/React等）
  - 高风险项目识别（得分<60的Top10）
  - 技术债务总览（严重/错误/警告数量和趋势）
  - AI审核价值分析（节省成本、避免损失、ROI）
```

**验收标准**：
- [ ] 公司质量总分（KPI级别，可设定年度目标）
- [ ] 部门对比雷达图或柱状图
- [ ] 语言质量分布（每种语言的平均分和项目数）
- [ ] 风险项目列表（Top10，按风险等级排序）
- [ ] 技术债务趋势（最近12个月）
- [ ] ROI分析（AI成本 vs 节省的人工成本 vs 避免的损失）

**ROI计算示例**：
- AI成本：约2万/月
- 节省人工Review时间：1200小时/月 × 300元/小时 = 36万/月
- 避免严重安全问题损失：234个 × 假设10%利用率 × 50万/次 = 约1170万/年
- ROI = (节省成本 - AI成本) / AI成本 × 100%

---

#### Story 11.8: 作为CTO，我希望能追踪年度质量改进目标
**优先级**: P1

**场景描述**：
```
Given 公司设定了年度质量目标
  例如：整体质量分从81提升到85分以上
When 我查看"目标追踪"
Then 我能看到：
  - 当前进度 vs 目标（进度条）
  - 各部门达成情况
  - 预测完成时间（基于当前趋势）
  - 风险预警（进度低于预期）
  - 改进建议
```

**验收标准**：
- [ ] 目标设定功能（公司级、部门级）
- [ ] 进度追踪仪表盘
- [ ] 部门达成率排行
- [ ] AI预测完成时间（基于历史趋势）
- [ ] 风险识别（红/黄/绿灯）
- [ ] 自动生成改进建议

---

#### Story 11.9: 作为高管，我希望能生成董事会级别的质量报告
**优先级**: P2

**场景描述**：
```
Given 需要向董事会汇报技术质量
When 我生成"高管报告"
Then 报告包含：
  - 核心指标卡片（质量分、债务量、改进幅度、ROI）
  - 趋势分析（同比、环比）
  - 重大风险和应对措施
  - 投入产出分析
  - 行业对标（可选）
And 报告格式为PPT，可直接使用
```

**验收标准**：
- [ ] 一键生成PPT报告（基于模板）
- [ ] 数据可视化（图表自动插入）
- [ ] 关键发现和建议（AI生成摘要）
- [ ] 支持自定义时间范围（月度/季度/年度）
- [ ] 支持自定义报告内容（勾选需要的章节）

---

#### Story 11.10: 作为平台管理员，我希望知道哪些规则最有价值
**优先级**: P1
**价值**: 优化规则库，去掉低效规则，提高审核质量

**场景描述**：
```
Given 平台有100+条规则
When 我查看"规则效能分析"
Then 我能看到：
  - 每条规则的触发频率
  - 每条规则的误报率（被标记为误报的比例）
  - 每条规则的修复率
  - 规则价值评分（综合指标）
  - 最有价值规则Top10
  - 需要优化的规则（误报率>30%）
  - 建议禁用的规则（价值分<50）
```

**验收标准**：
- [ ] 规则触发统计（按天/周/月）
- [ ] 误报率计算（误报次数 / 触发次数）
- [ ] 修复率统计（修复次数 / 触发次数）
- [ ] 价值评分公式：价值分 = 触发频率 × 严重程度系数 × 修复率 × (1 - 误报率) × 100
- [ ] 建议列表（禁用/优化/保留）
- [ ] 规则使用热力图（按分类统计）
- [ ] 规则详细分析页（单个规则的深度分析）

**价值评分说明**：
- 触发频率：归一化到0-1（触发次数 / 最大触发次数）
- 严重程度系数：CRITICAL=3, ERROR=2, WARNING=1
- 修复率：修复次数 / 触发次数
- 误报率：误报次数 / 触发次数

---

#### Story 11.11: 作为规则维护者，我希望能A/B测试新规则
**优先级**: P2

**场景描述**：
```
Given 我创建了一条新规则
When 我启用"A/B测试模式"
Then 新规则只对50%的审核生效
And 我能对比：
  - 新规则的触发率
  - 误报率
  - 开发者反馈
And 决定是否全量发布或优化规则
```

**验收标准**：
- [ ] A/B测试开关
- [ ] 流量分配配置（10%/50%/90%可选）
- [ ] 对比报告（实验组 vs 对照组）
- [ ] 开发者反馈收集（点赞/点踩）
- [ ] 一键全量发布或回滚

---

#### Story 11.12: 作为产品经理，我希望知道自定义规则的使用情况
**优先级**: P2

**场景描述**：
```
Given 团队创建了自定义规则
When 我查看"自定义规则分析"
Then 我能看到：
  - 哪些团队/部门创建了规则
  - 自定义规则的质量（误报率、价值分）
  - 规则复用情况（被其他团队使用的次数）
  - 优秀规则推荐（可推广到规则市场）
```

**验收标准**：
- [ ] 自定义规则列表（按创建时间/使用次数排序）
- [ ] 规则质量评分
- [ ] 复用次数统计
- [ ] 推荐到规则市场功能
- [ ] 规则分享和收藏

---

#### Story 11.13: 作为管理者，我希望能对比不同维度的数据
**优先级**: P1

**场景描述**：
```
Given 我想了解不同维度的质量差异
When 我使用"对比分析"功能
Then 我能选择：
  - 部门对比（后端部 vs 前端部 vs 算法部）
  - 项目对比（项目A vs 项目B）
  - 时间对比（本月 vs 上月 vs 去年同期）
  - 语言对比（Java vs Go vs Python）
And 看到直观的对比图表（雷达图/柱状图/表格）
And 能导出对比报告
```

**验收标准**：
- [ ] 灵活的对比维度选择（最多选择5个对象）
- [ ] 雷达图对比（多维能力）
- [ ] 柱状图对比（单维度）
- [ ] 表格对比（详细数据）
- [ ] 差异高亮（颜色标注差异大的项）
- [ ] 导出对比报告（PDF/Excel）
- [ ] AI生成对比洞察和建议

---

#### Story 11.14: 作为用户，我希望能导出和分享数据
**优先级**: P2

**场景描述**：
```
Given 我想分享数据给其他人
When 我点击"导出"或"分享"
Then 我能：
  - 导出Excel报告（带图表）
  - 导出PDF报告（格式化）
  - 生成分享链接（带权限控制和有效期）
  - 定期邮件订阅（每周/每月自动发送）
```

**验收标准**：
- [ ] Excel导出（包含图表，可在Excel中编辑）
- [ ] PDF导出（格式化，适合打印）
- [ ] 分享链接（临时访问，可设置有效期1天/7天/30天）
- [ ] 邮件订阅功能（可选时间和频率）
- [ ] 权限控制（分享时可设置只读/可编辑）

---

### Epic 12: 平台基础功能

#### Story 12.1: 作为管理员，我希望能添加和管理Git仓库服务
**优先级**: P0
**价值**: 让项目能接入审核平台

**场景描述**：
```
Given 我有一个GitLab项目需要代码审核
When 我进入"服务管理"页面
Then 我可以：
  - 点击"添加服务"按钮
  - 填写服务基本信息（名称、Git平台、仓库URL、Project ID）
  - 填写Access Token
  - 点击"测试连接"验证配置
  - 保存后自动配置Webhook
And 系统显示配置成功提示
And Webhook立即生效
```

**验收标准**：
- [ ] 支持GitLab和GitHub两种平台
- [ ] 自动验证Access Token权限（api, read_repository等）
- [ ] 自动配置Webhook到Git平台
- [ ] Webhook签名密钥自动生成
- [ ] 配置测试功能（测试连接和权限）
- [ ] 支持配置审核触发条件（Push/MR/PR）
- [ ] 支持配置审核分支（main, release/*等，支持通配符）
- [ ] 错误提示清晰（权限不足、URL错误等）

**界面要点**：
- 表单分步引导（基本信息 → 凭证配置 → 审核设置 → 测试验证）
- 实时验证（URL格式、Token有效性）
- 一键复制Webhook URL和Secret

---

#### Story 12.2: 作为用户，我希望能查询和筛选审核记录
**优先级**: P0
**价值**: 方便回溯历史审核结果

**场景描述**：
```
Given 系统已经积累了大量审核记录
When 我进入"审核记录"页面
Then 我能看到：
  - 审核记录列表（时间倒序）
  - 每条记录显示：服务名、分支、作者、得分、问题数、时间
And 我可以筛选：
  - 按服务筛选
  - 按分支筛选
  - 按作者筛选
  - 按得分范围筛选（<60, 60-80, >80）
  - 按时间范围筛选
And 我可以排序：
  - 按时间排序
  - 按得分排序
And 点击记录可查看详情
```

**验收标准**：
- [ ] 列表分页（每页20条）
- [ ] 多维度筛选器（服务/分支/作者/得分/时间）
- [ ] 搜索功能（模糊搜索服务名、分支名、作者）
- [ ] 快速筛选标签（严重问题、低分审核、我的审核）
- [ ] 排序功能（时间/得分）
- [ ] 批量操作（批量导出、批量重新审核）
- [ ] 记录详情快速预览（悬浮卡片）
- [ ] 支持URL参数（方便分享筛选结果）

**性能要求**：
- 列表加载<1秒
- 筛选响应<500ms
- 支持10万+条记录

---

#### Story 12.3: 作为开发者，我希望能管理项目的基线
**优先级**: P1
**价值**: 区分新增问题和历史问题

**场景描述**：
```
Given 我的项目已经运行了一段时间，存在历史遗留问题
When 我进入项目的"基线管理"
Then 我可以：
  - 查看当前基线信息（基线commit、创建时间、问题数）
  - 创建新基线（选择一个commit作为基线）
  - 查看基线历史记录
  - 对比不同基线的差异
And 新基线创建后：
  - 后续审核只报告相对于基线的新增问题
  - 基线之前的问题归档为"历史债务"
```

**验收标准**：
- [ ] 基线创建功能（选择commit或当前HEAD）
- [ ] 基线信息展示（commit hash、分支、时间、问题快照）
- [ ] 基线历史列表
- [ ] 基线对比功能（问题增减情况）
- [ ] 基线切换功能
- [ ] 基线删除功能（需二次确认）
- [ ] 自动建议创建基线（项目首次接入时）

**数据结构**：
```typescript
interface Baseline {
  id: string
  projectId: string
  commitHash: string
  branch: string
  createdAt: Date
  createdBy: string

  // 基线快照
  totalIssues: number
  criticalIssues: number
  errorIssues: number
  warningIssues: number

  // 问题详情（用于对比）
  issuesSnapshot: Issue[]
}
```

---

#### Story 12.4: 作为开发者，我希望能标记和管理误报
**优先级**: P1
**价值**: 减少误报干扰，优化规则

**场景描述**：
```
Given AI审核报告了一个问题
When 我认为这是误报
Then 我可以：
  - 点击"标记为误报"按钮
  - 填写误报原因（可选）
  - 选择误报类型（规则问题/AI理解错误/其他）
And 该问题被标记后：
  - 在当前审核中隐藏或标注"已标记误报"
  - 该文件的该位置的相同问题不再报告
  - 规则维护者能看到误报统计
And 我可以查看我标记的所有误报记录
```

**验收标准**：
- [ ] 误报标记功能（带原因填写）
- [ ] 误报类型分类（规则问题/AI错误/特殊场景/其他）
- [ ] 误报记录管理（查看、撤销）
- [ ] 误报统计（按规则/按用户/按项目）
- [ ] 管理员审核误报（确认/驳回）
- [ ] 基于误报自动优化规则（建议禁用高误报规则）
- [ ] 误报模式识别（相似代码自动忽略）

**权限控制**：
- 普通开发者：可标记自己提交代码的误报
- Tech Lead：可标记项目内所有误报
- 管理员：可管理全局误报

---

#### Story 12.5: 作为管理员，我希望能监控审核任务队列
**优先级**: P1
**价值**: 了解系统负载，及时处理异常

**场景描述**：
```
Given 系统正在处理多个审核任务
When 我进入"队列监控"页面
Then 我能看到：
  - 实时队列状态（待处理、处理中、已完成、失败）
  - 队列长度趋势图
  - 正在处理的任务列表（任务ID、服务、进度、耗时）
  - 失败任务列表（失败原因、重试次数）
And 我可以：
  - 手动重试失败任务
  - 取消排队任务
  - 调整任务优先级
  - 查看任务详细日志
```

**验收标准**：
- [ ] 队列实时统计（待处理/处理中/完成/失败数量）
- [ ] 队列长度趋势图（最近24小时）
- [ ] 正在处理任务列表（实时进度）
- [ ] 失败任务列表（含失败原因）
- [ ] 任务操作（重试/取消/提升优先级）
- [ ] 任务日志查看（详细执行日志）
- [ ] 性能监控（平均耗时、成功率）
- [ ] 告警功能（队列堆积、失败率过高）

**监控指标**：
- 队列长度
- 平均等待时间
- 平均处理时间
- 成功率
- 失败率
- 重试次数

---

#### Story 12.6: 作为管理员，我希望能配置审核超时和重试策略
**优先级**: P1

**场景描述**：
```
Given 不同项目的代码量差异很大
When 我配置审核策略
Then 我可以设置：
  - 全局超时时间（默认10分钟）
  - 项目级超时时间（大项目可设置更长）
  - 重试次数（默认3次）
  - 重试间隔（指数退避）
  - 失败通知策略
```

**验收标准**：
- [ ] 全局超时配置
- [ ] 项目级超时配置（覆盖全局）
- [ ] 重试策略配置（次数、间隔）
- [ ] 失败通知配置（通知谁、何时通知）
- [ ] 优先级队列配置（VIP项目优先）
- [ ] 并发控制（限制同时处理的任务数）

---

#### Story 12.7: 作为用户，我希望能查看审核任务的实时进度
**优先级**: P2

**场景描述**：
```
Given 我提交了代码触发审核
When 审核正在进行中
Then 我能看到：
  - 审核进度条（0-100%）
  - 当前阶段（克隆代码/分析文件/AI审核/生成报告）
  - 预计剩余时间
And 审核完成后：
  - 自动跳转到审核详情
  - 企业微信通知
```

**验收标准**：
- [ ] 实时进度显示（WebSocket推送）
- [ ] 阶段展示（克隆/分析/审核/报告）
- [ ] 进度百分比
- [ ] 预计剩余时间（基于历史数据）
- [ ] 完成后自动跳转
- [ ] 支持在审核记录页面查看进度

---

#### Story 12.8: 作为Tech Lead，我希望能批量管理服务配置
**优先级**: P2

**场景描述**：
```
Given 我管理多个相似的微服务
When 我需要统一配置审核规则
Then 我可以：
  - 选择多个服务
  - 批量应用规则模板
  - 批量修改配置（如审核分支）
  - 批量启用/禁用审核
```

**验收标准**：
- [ ] 服务多选功能
- [ ] 批量应用规则模板
- [ ] 批量配置修改
- [ ] 批量启用/禁用
- [ ] 配置预览（批量操作前预览）
- [ ] 操作日志记录

---

### Epic 13: 权限和安全增强

#### Story 13.1: 作为管理员，我希望能精细控制用户权限
**优先级**: P1
**价值**: 保证数据安全和职责分离

**场景描述**：
```
Given 平台有多种角色和权限需求
When 我进入"权限管理"
Then 我可以：
  - 查看所有角色及其权限
  - 创建自定义角色
  - 为角色分配权限
  - 为用户分配角色
  - 查看权限矩阵
```

**角色定义**：
```typescript
enum Role {
  SUPER_ADMIN = 'SUPER_ADMIN',      // 超级管理员：所有权限
  ORG_ADMIN = 'ORG_ADMIN',          // 组织管理员：管理整个公司
  DEPT_ADMIN = 'DEPT_ADMIN',        // 部门管理员：管理本部门
  PROJECT_OWNER = 'PROJECT_OWNER',  // 项目负责人：管理项目配置
  DEVELOPER = 'DEVELOPER',          // 开发者：查看和标记误报
  VIEWER = 'VIEWER'                 // 访客：只读权限
}

enum Permission {
  // 服务管理
  SERVICE_CREATE = 'service:create',
  SERVICE_UPDATE = 'service:update',
  SERVICE_DELETE = 'service:delete',
  SERVICE_VIEW = 'service:view',

  // 审核管理
  REVIEW_VIEW = 'review:view',
  REVIEW_TRIGGER = 'review:trigger',
  REVIEW_MARK_FALSE_POSITIVE = 'review:mark-false-positive',

  // 规则管理
  RULE_CREATE = 'rule:create',
  RULE_UPDATE = 'rule:update',
  RULE_DELETE = 'rule:delete',
  RULE_VIEW = 'rule:view',

  // 数据分析
  ANALYTICS_VIEW_SELF = 'analytics:view-self',
  ANALYTICS_VIEW_TEAM = 'analytics:view-team',
  ANALYTICS_VIEW_DEPT = 'analytics:view-dept',
  ANALYTICS_VIEW_COMPANY = 'analytics:view-company',

  // 系统管理
  USER_MANAGE = 'user:manage',
  ROLE_MANAGE = 'role:manage',
  AI_MODEL_MANAGE = 'ai-model:manage',
  QUEUE_MANAGE = 'queue:manage'
}
```

**验收标准**：
- [ ] 预定义6种角色（如上）
- [ ] 自定义角色功能
- [ ] 权限矩阵展示
- [ ] 用户-角色分配
- [ ] 项目级权限（某用户只能管理特定项目）
- [ ] 权限继承（部门管理员自动拥有部门内项目权限）
- [ ] 权限审计日志
- [ ] 最小权限原则检查

---

#### Story 13.2: 作为管理员，我希望能审计所有敏感操作
**优先级**: P1

**场景描述**：
```
Given 需要追溯用户操作
When 发生问题时
Then 我可以查看审计日志：
  - 谁在什么时间
  - 做了什么操作
  - 操作的对象
  - 操作结果（成功/失败）
  - IP地址
```

**验收标准**：
- [ ] 记录所有敏感操作（配置修改、权限变更、数据导出等）
- [ ] 日志包含：用户、时间、操作、对象、结果、IP
- [ ] 日志查询和筛选
- [ ] 日志导出
- [ ] 日志保留策略（至少保留1年）
- [ ] 异常操作告警（如深夜操作、批量删除等）

---

#### Story 13.3: 作为开发者，我希望平台能自动检测代码中的敏感信息泄漏
**优先级**: P1
**价值**: 防止密钥、密码等敏感信息泄漏到Git仓库

**场景描述**：
```
Given 我不小心在代码中硬编码了密码
When 提交代码触发审核
Then 平台能检测到：
  - API Key (AWS_ACCESS_KEY等)
  - 密码 (password = "xxx")
  - 数据库连接串
  - 私钥文件
  - JWT Secret
And 立即阻止合并
And 发送告警通知
```

**验收标准**：
- [ ] 内置敏感信息正则规则（API Key、Password、Token等）
- [ ] 支持自定义敏感信息规则
- [ ] 高置信度检测（减少误报）
- [ ] 阻止合并功能
- [ ] 告警通知（安全团队）
- [ ] 敏感信息发现历史记录
- [ ] 修复建议（使用环境变量、配置中心等）

**检测规则示例**：
```typescript
const sensitivePatterns = [
  {
    name: 'AWS Access Key',
    pattern: /AKIA[0-9A-Z]{16}/,
    severity: 'CRITICAL'
  },
  {
    name: 'Generic API Key',
    pattern: /['"]?api[_-]?key['"]?\s*[:=]\s*['"][a-zA-Z0-9]{20,}['"]/i,
    severity: 'CRITICAL'
  },
  {
    name: 'Database Password',
    pattern: /['"]?password['"]?\s*[:=]\s*['"].{8,}['"]/i,
    severity: 'CRITICAL'
  },
  // ... 更多规则
]
```

---

## 3. 功能优先级规划

### P0 - 核心功能（必须有，1-2个月）

| 功能模块 | Story | 预计工作量 | 备注 |
|---------|-------|-----------|------|
| Git集成 | 1.1, 1.2, 1.3 | 2周 | GitLab + GitHub |
| 多语言支持 | 2.1-2.5 | 3周 | Java/Go/React/C/Python |
| 审核引擎 | - | 2周 | 核心逻辑 |
| AI模型管理 | 4.1 | 1周 | 配置和调度 |
| Web管理后台 | - | 3周 | 基础页面 |
| 企业微信通知 | 6.1 | 3天 | 基础通知 |
| **服务管理** | **12.1** | **1周** | **添加和管理Git仓库** |
| **审核记录查询** | **12.2** | **1周** | **查询和筛选** |
| **敏感信息检测** | **13.3** | **3天** | **防止密钥泄漏** |

**里程碑**: 2个月后可用，覆盖基本审核流程

---

### P1 - 重要功能（应该有，3-4个月）

| 功能模块 | Story | 预计工作量 | 备注 |
|---------|-------|-----------|------|
| 规则管理 | 3.1, 3.2 | 2周 | 自定义规则 |
| 技术债务 | 5.1, 5.2 | 2周 | 债务可视化 |
| AI监控 | 4.2 | 1周 | 使用统计 |
| 多级通知 | 6.2 | 1周 | 灵活配置 |
| 权限管理 | 7.1, 7.2 | 2周 | 多租户 |
| 用户中心集成 | - | 1周 | SSO登录 |
| **用户质量中心** | **11.1, 11.2** | **2周** | **个人画像和项目视图** |
| **部门质量看板** | **11.4, 11.5** | **2周** | **部门管理视角** |
| **公司全局看板** | **11.7, 11.8** | **2周** | **高层决策视角** |
| **规则效能分析** | **11.10** | **1周** | **规则价值评估** |
| **对比分析** | **11.13** | **1周** | **多维度对比** |
| **基线管理** | **12.3** | **1周** | **区分新增和历史问题** |
| **误报管理** | **12.4** | **1周** | **标记和管理误报** |
| **队列监控** | **12.5** | **1周** | **任务队列监控** |
| **审核策略配置** | **12.6** | **3天** | **超时和重试** |
| **精细权限控制** | **13.1** | **1周** | **RBAC权限体系** |
| **审计日志** | **13.2** | **3天** | **操作审计** |

**里程碑**: 4个月后功能完善，可以大规模推广

---

### P2 - 优化功能（最好有，6个月+）

| 功能模块 | Story | 预计工作量 | 备注 |
|---------|-------|-----------|------|
| 规则模板市场 | 3.3 | 1周 | 社区生态 |
| 专家审核 | 8.1 | 2周 | 工作流 |
| IDE插件 | 9.1 | 4周 | VSCode + IDEA |
| 报表系统 | 10.1 | 2周 | 周报月报 |
| 多AI共识 | - | 1周 | 提高准确率 |
| **质量排行榜** | **11.3** | **1周** | **游戏化激励** |
| **技能分析** | **11.6** | **1周** | **团队技能短板识别** |
| **高管报告** | **11.9** | **3天** | **董事会级报告** |
| **规则A/B测试** | **11.11** | **1周** | **规则优化** |
| **自定义规则分析** | **11.12** | **3天** | **规则市场生态** |
| **数据导出分享** | **11.14** | **1周** | **Excel/PDF/链接分享** |
| **实时进度显示** | **12.7** | **1周** | **WebSocket进度推送** |
| **批量服务管理** | **12.8** | **3天** | **批量配置** |

**里程碑**: 6个月后体验完善，功能全面

---

## 4. 核心页面设计

### 4.1 服务管理页

**功能**：添加和管理Git仓库

**核心元素**：
- 服务列表（表格）
- 搜索和筛选
- 添加服务按钮
- 服务状态指示

**交互流程**：
```
点击"添加服务"
  ↓
填写表单：
  - 服务名称
  - Git平台（GitLab/GitHub）
  - 仓库URL
  - Project ID
  - Access Token
  ↓
点击"测试连接"
  ↓
测试通过 → 自动配置Webhook
  ↓
保存成功 → 返回列表
```

---

### 4.2 审核记录页

**功能**：查看审核历史

**核心元素**：
- 记录列表（时间倒序）
- 筛选器（服务/分支/作者/得分）
- 得分可视化（进度条）
- 快速操作（查看详情）

**列表项设计**：
```
┌─────────────────────────────────────────┐
│ 2025-01-15 10:23                        │
│ user-service / feature/payment          │
│ 作者: 张三                               │
│                                         │
│ 得分: ████████░░ 82/100 ⚠️              │
│ 问题: 严重1 错误3 警告5                  │
│                                         │
│ [查看详情] [重新审核]                    │
└─────────────────────────────────────────┘
```

---

### 4.3 审核详情页（最重要）

**功能**：查看具体问题和代码

**布局**：
```
┌─────────────────────────────────────────┐
│ user-service @ abc123def                │
│ feature/payment-refactor                │
│ 得分: 82/100  耗时: 2分30秒              │
├─────────────────────────────────────────┤
│ 左侧: 代码Diff (Monaco Editor)          │
│ - 高亮显示问题行                         │
│ - 点击行号展开问题详情                   │
│ - 支持文件切换                           │
│                                         │
│ 右侧: 问题列表                           │
│ ┌─ 严重问题 (1) ──────────────┐        │
│ │ ❌ SQL注入风险                │        │
│ │    UserService.java:45       │        │
│ │    [查看代码] [标记误报]     │        │
│ └─────────────────────────────┘        │
│                                         │
│ ┌─ 错误 (3) ────────────────┐          │
│ │ ...                         │          │
│ └─────────────────────────────┘        │
└─────────────────────────────────────────┘
```

---

### 4.4 技术债务看板

**功能**：可视化技术债务

**核心元素**：
- 债务总分卡片
- 趋势图表
- 文件热力图
- 优化建议

---

### 4.5 规则管理页

**功能**：管理审核规则

**核心元素**：
- 规则分类树（左侧）
- 规则列表（右侧）
- 规则编辑器（弹窗）
- 规则测试工具

---

### 4.6 AI模型配置页

**功能**：配置和监控AI模型

**核心元素**：
- 模型卡片列表
- 实时监控（并发使用率）
- 添加/编辑模型表单
- 测试连接按钮

---

## 5. 非功能性需求

### 5.1 性能要求

| 指标 | 目标 | 备注 |
|------|------|------|
| 审核启动时间 | <5分钟 | 从Push到开始审核 |
| 小型审核（<5个文件） | <2分钟 | 完成审核 |
| 大型审核（>20个文件） | <10分钟 | 完成审核 |
| Web页面加载 | <2秒 | 首屏 |
| API响应时间 | <200ms | P95 |
| 队列吞吐量 | >100个/小时 | 高峰期 |

### 5.2 可用性要求

- **系统可用性**: >99%
- **数据持久性**: >99.99%
- **错误恢复**: 自动重试失败任务
- **优雅降级**: AI服务故障时，任务标记为"待人工审核"

### 5.3 安全要求

- **敏感信息检测**: 自动检测密码/密钥泄漏
- **数据加密**: Token和API Key加密存储
- **审计日志**: 所有操作可追溯
- **权限控制**: 基于RBAC的细粒度权限
- **数据隔离**: 多租户数据完全隔离

### 5.4 可扩展性

- **水平扩展**: 支持多实例部署
- **队列扩展**: Redis队列支持集群
- **AI扩展**: 支持添加新的AI模型
- **语言扩展**: 插件化语言支持

---

## 6. 技术约束

### 6.1 已确定的技术选型

- **Git平台**: GitLab（私有部署） + GitHub
- **AI模型**: 本地部署（OpenAI兼容API）+ 外部API（可选）
- **认证**: 企业用户中心 + SSO（企业微信登录）
- **通知**: 企业微信机器人

### 6.2 技术限制

- **AI并发**: 需要可配置，受GPU资源限制
- **部署方式**: 企业内网部署
- **数据存储**: 需要符合企业数据安全规范

---

## 7. 里程碑规划

### 阶段1: MVP (2个月)
**目标**: 核心功能可用，完成基本审核流程

**交付物**:
- ✅ GitLab + GitHub集成
- ✅ Java/Go/React审核能力
- ✅ Web管理后台（基础版）
- ✅ 企业微信通知
- ✅ 基础权限管理
- ✅ 服务管理和审核记录查看

**验收标准**:
- 3个项目接入
- 每天审核50+次
- 识别准确率>70%
- 平台稳定性>95%

---

### 阶段2: 功能完善 (4个月)
**目标**: 大规模推广，数据分析能力完善

**交付物**:
- ✅ C/Python支持
- ✅ 自定义规则
- ✅ 技术债务管理
- ✅ 多级通知配置
- ✅ 用户中心集成
- ✅ 完整权限体系
- ✅ **用户质量中心**（个人画像、项目视图）
- ✅ **部门质量看板**（部门管理视角）
- ✅ **公司全局看板**（高层决策视角）
- ✅ **规则效能分析**（规则价值评估）
- ✅ **对比分析**（多维度对比）

**验收标准**:
- 20个项目接入
- 覆盖80%的代码仓库
- 技术债务可视化
- 用户满意度>75%
- **质量数据完整性>95%**

---

### 阶段3: 体验优化 (6个月)
**目标**: 开发者喜欢用，功能体验全面

**交付物**:
- ✅ IDE插件（VSCode + IDEA）
- ✅ 专家审核流程
- ✅ 报表系统
- ✅ 规则模板市场
- ✅ 多AI共识
- ✅ **质量排行榜**（游戏化激励）
- ✅ **技能分析**（团队技能短板识别）
- ✅ **高管报告**（董事会级报告）
- ✅ **规则A/B测试**（规则优化）
- ✅ **数据导出分享**（Excel/PDF/链接）

**验收标准**:
- 50个项目接入
- 开发者满意度>80%
- IDE插件使用率>50%
- **质量改进可见**（平均分提升>10分）

---

## 8. 成功指标

### 业务指标

| 指标 | 目标（3个月） | 目标（6个月） |
|------|--------------|--------------|
| 接入项目数 | 20个 | 50个 |
| 日均审核次数 | 200次 | 500次 |
| 发现问题数 | 1000+个 | 5000+个 |
| 严重问题阻止率 | 100% | 100% |

### 质量指标

| 指标 | 目标 |
|------|------|
| 识别准确率 | >80% |
| 误报率 | <15% |
| 开发者满意度 | >75% |
| 平台可用性 | >99% |

### 效能指标

| 指标 | 目标 |
|------|------|
| 人工Review时间节省 | 50% |
| 技术债务下降 | 20% |
| 代码质量平均分提升 | +10分 |

---

## 9. 风险和挑战

### 风险1: AI准确率不足
**影响**: 误报太多，开发者不信任
**应对**:
- 初期降低标准，只报告CRITICAL问题
- 收集反馈，持续优化Prompt
- 支持"标记误报"功能

### 风险2: 审核速度慢
**影响**: 阻塞开发流程
**应对**:
- 队列优先级机制
- 智能跳过非关键文件
- 增加AI并发数

### 风险3: 开发者抵触
**影响**: 不愿意接入
**应对**:
- 初期不强制，先试点
- 强调"辅助"而非"监督"
- 提供价值（学习最佳实践）

### 风险4: 成本过高
**影响**: 预算超支
**应对**:
- 优先使用本地模型
- 缓存机制减少重复审核
- 按需使用外部AI

---

**本PRD状态**: v3.0 完整版
**下一步行动**:
1. ✅ Epic 11（多维度审核分析）已整合
2. ✅ Epic 12（平台基础功能）已补充
3. ✅ Epic 13（权限和安全增强）已补充
4. 评审PRD，确认需求优先级
5. 细化Story，拆分成Task
6. 数据模型设计
7. 技术方案设计
8. 启动开发

**变更记录**:
- 2025-01-28 v3.0:
  - 新增Epic 12（平台基础功能）：补充服务管理、审核记录查询、基线管理、误报管理、队列监控等8个Story
  - 新增Epic 13（权限和安全增强）：补充精细权限控制、审计日志、敏感信息检测等3个Story
  - 更新优先级规划，将Epic 12-13的11个Story纳入P0/P1/P2
  - 完善数据模型和权限控制代码示例
  - 当前包含13个Epic，80+个User Story
- 2025-01-28 v2.0: 整合Epic 11（多维度审核分析），新增14个User Story，涵盖用户/部门/公司/规则四个视角
- 2025-01-15 v1.0: 初始版本，包含Epic 1-10

---

## 11. 数据模型补充

### 11.1 质量快照数据模型

为支持多维度分析，需要增加以下数据结构：

```typescript
// 用户质量快照（每日计算）
interface UserQualitySnapshot {
  id: string
  userId: string
  date: Date

  // 质量指标
  overallScore: number      // 综合得分 (0-100)
  securityScore: number     // 安全性得分 (0-100)
  qualityScore: number      // 质量得分 (0-100)
  performScore: number      // 性能得分 (0-100)
  styleScore: number        // 规范性得分 (0-100)

  // 统计指标
  reviewCount: number       // 审核次数
  issueCount: number        // 问题数
  fixedCount: number        // 修复数

  // 问题分布
  criticalCount: number     // 严重问题数
  errorCount: number        // 错误数
  warningCount: number      // 警告数

  // 排名
  rankInTeam?: number       // 团队排名
  rankInDept?: number       // 部门排名
  rankInCompany?: number    // 公司排名
}

// 部门质量快照（每日计算）
interface DepartmentQualitySnapshot {
  id: string
  departmentId: string
  date: Date

  overallScore: number
  memberCount: number
  projectCount: number
  reviewCount: number

  // 分布统计
  scoreDistribution: {
    'excellent': number    // >90分的人数
    'good': number         // 70-90分的人数
    'needImprovement': number  // <70分的人数
  }

  // 问题统计
  totalIssues: number
  criticalIssues: number
  errorIssues: number
  warningIssues: number

  rankInCompany?: number
}

// 公司质量快照（每日计算）
interface CompanyQualitySnapshot {
  id: string
  date: Date

  overallScore: number
  departmentCount: number
  memberCount: number
  projectCount: number

  // 语言分布
  languageScores: {
    [language: string]: {
      score: number
      projectCount: number
    }
  }

  // 技术债务
  totalDebt: number
  criticalDebt: number
  errorDebt: number
  warningDebt: number
}

// 规则效能统计（每日计算）
interface RuleEffectivenessSnapshot {
  id: string
  ruleId: string
  date: Date

  triggerCount: number      // 触发次数
  falsePositive: number     // 误报次数
  fixedCount: number        // 修复次数
  ignoredCount: number      // 忽略次数

  // 计算指标
  falsePositiveRate: number  // 误报率 (0-1)
  fixRate: number            // 修复率 (0-1)
  valueScore: number         // 价值分 (0-100)
}

// 项目质量快照
interface ProjectQualitySnapshot {
  id: string
  projectId: string
  date: Date

  overallScore: number
  reviewCount: number
  contributorCount: number

  // 各维度得分
  securityScore: number
  qualityScore: number
  performScore: number
  styleScore: number

  // 技术债务
  debtScore: number
  criticalIssues: number
  errorIssues: number
  warningIssues: number
}
```

### 11.2 数据聚合任务

```typescript
// 每日凌晨2点执行
@Cron('0 2 * * *')
async calculateDailySnapshots() {
  const yesterday = new Date()
  yesterday.setDate(yesterday.getDate() - 1)

  // 1. 计算用户快照
  await this.calculateUserSnapshots(yesterday)

  // 2. 计算项目快照
  await this.calculateProjectSnapshots(yesterday)

  // 3. 计算部门快照
  await this.calculateDepartmentSnapshots(yesterday)

  // 4. 计算公司快照
  await this.calculateCompanySnapshot(yesterday)

  // 5. 计算规则效能
  await this.calculateRuleEffectiveness(yesterday)
}

// 质量分数计算公式
function calculateQualityScore(issues: Issue[]): QualityScores {
  const weights = {
    CRITICAL: 10,
    ERROR: 5,
    WARNING: 1
  }

  const totalWeight = issues.reduce((sum, issue) => {
    return sum + weights[issue.severity]
  }, 0)

  // 基础分100，每个问题按权重扣分
  const score = Math.max(0, 100 - totalWeight)

  return {
    overall: score,
    security: calculateDimensionScore(issues, 'security'),
    quality: calculateDimensionScore(issues, 'quality'),
    performance: calculateDimensionScore(issues, 'performance'),
    style: calculateDimensionScore(issues, 'style')
  }
}
```

### 11.3 缓存策略

```typescript
// 实时查询用户质量时使用缓存
async getUserQuality(userId: string) {
  const cacheKey = `user:quality:${userId}`

  // 1. 先查Redis缓存（TTL 1小时）
  const cached = await this.redis.get(cacheKey)
  if (cached) {
    return JSON.parse(cached)
  }

  // 2. 查询数据库（最近一次快照 + 今日实时数据）
  const latestSnapshot = await this.getLatestUserSnapshot(userId)
  const todayReviews = await this.getTodayReviews(userId)

  // 3. 合并计算
  const quality = this.mergeQualityData(latestSnapshot, todayReviews)

  // 4. 写入缓存
  await this.redis.setex(cacheKey, 3600, JSON.stringify(quality))

  return quality
}
```

### 11.4 权限控制

```typescript
// 数据访问权限控制
class QualityDataAccessControl {
  // 检查用户是否能访问部门数据
  async canAccessDepartmentData(userId: string, deptId: string): Promise<boolean> {
    const user = await this.getUserWithRoles(userId)

    // Super Admin可以访问所有数据
    if (user.role === 'SUPER_ADMIN') return true

    // Org Admin可以访问所有部门
    if (user.role === 'ORG_ADMIN') return true

    // Dept Admin只能访问自己的部门
    if (user.role === 'DEPT_ADMIN') {
      return user.departmentId === deptId
    }

    // 普通用户不能访问部门数据
    return false
  }

  // 检查用户是否能访问公司全局数据
  async canAccessCompanyData(userId: string): Promise<boolean> {
    const user = await this.getUserWithRoles(userId)
    return ['SUPER_ADMIN', 'ORG_ADMIN'].includes(user.role)
  }
}
```

---

## 12. 附录

### A. 名词解释

- **MR (Merge Request)**: GitLab的代码合并请求
- **PR (Pull Request)**: GitHub的代码合并请求
- **Webhook**: Git平台的事件回调机制
- **Token**: API访问凭证
- **Prompt**: AI的输入指令模板
- **基线**: 用于对比的参考版本

### B. 参考资料

- [GitLab Webhooks文档](https://docs.gitlab.com/ee/user/project/integrations/webhooks.html)
- [GitHub Webhooks文档](https://docs.github.com/en/webhooks)
- [OpenAI API兼容标准](https://platform.openai.com/docs/api-reference)

---

**本PRD状态**: 草稿 v1.0
**下一步行动**:
1. 评审PRD，确认需求优先级
2. 细化Story，拆分成Task
3. 技术方案设计
4. 启动开发

**变更记录**:
- 2025-xx-xx: 初始版本
